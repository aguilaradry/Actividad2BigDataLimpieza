## proyecto_integrador_edwin_sanchez_nikol_tamayo_adriana_aguilar

## Actividad 1: Proyecto de Ingesta de Datos desde una API a SQLite

### DescripciÃ³n del Proyecto  

Este proyecto automatiza la extracciÃ³n, almacenamiento y validaciÃ³n de datos desde la API [Sample APIs - Nintendo Switch Games](https://api.sampleapis.com/switch/games) hacia una base de datos SQLite, generando ademÃ¡s archivos de auditorÃ­a y evidencia en Excel. Todo el desarrollo se realizÃ³ en **GitHub Codespaces**.

La automatizaciÃ³n se realiza mediante **GitHub Actions**, garantizando que los datos se actualicen sin intervenciÃ³n manual.  


### MetodologÃ­a de Desarrollo  

#### **ExtracciÃ³n de Datos desde el API**  
- Se seleccionÃ³ la API de videojuegos de Nintendo Switch.
- Se creÃ³ un script en Python para consumir la API usando `requests`.  
- Se procesaron los datos extraÃ­dos asegurando su correcta estructura. 

#### **Almacenamiento en Base de Datos SQLite**  
- Se creÃ³ una base de datos en `src/bigdata/static/db/ingestion.db`.
- Se diseÃ±Ã³ un esquema con una tabla `videojuegos` para almacenar los datos.
- Se insertaron los datos extraÃ­dos de la API en la base de datos.

#### **GeneraciÃ³n de Evidencias**  
- **Archivo Excel**: Se usa `pandas` para exportar los datos a `ingestion.xlsx`.  
- **Archivo de AuditorÃ­a**: Se compara la cantidad de registros obtenidos de la API y los almacenados en la base de datos. 

#### **AutomatizaciÃ³n con GitHub Actions**  
- Se configurÃ³ un **workflow** que ejecuta la extracciÃ³n, almacenamiento y generaciÃ³n de evidencias automÃ¡ticamente.  
- Se verifica que la base de datos y los archivos generados sean correctos.  


### ðŸ“‚ Estructura del Proyecto  

[proyecto_integrador_edwin_sanchez_nikol_tamayo_adriana_aguilar]
â”œâ”€â”€ setup.py
â”œâ”€â”€ README.md
â”œâ”€â”€ .github
â”‚   â””â”€â”€ workflows
â”‚       â””â”€â”€ test_actividad1.yml
â””â”€â”€ src
    â”œâ”€â”€ static
    â”‚   â”œâ”€â”€ auditoria
    â”‚   â”‚   â””â”€â”€ ingestion.txt
    â”‚   â”œâ”€â”€ db
    â”‚   â”‚   â””â”€â”€ ingestion.db
    â”‚   â””â”€â”€ xlsx
    â”‚       â””â”€â”€ ingestion.xlsx
    â””â”€â”€ ingestion.py

### **AutomatizaciÃ³n con GitHub Actions**
El proyecto usa GitHub Actions para ejecutar la ingesta de datos automÃ¡ticamente.
Srchivo: .github/workflows/test_actividad1.yml
- Se crea un entorno virtual (python -m venv venv)
- Se activa el entorno virtual (./venv/Scripts/activate )
- Se actualiza pip (pip install --upgrade pip)
- InstalaciÃ³n de dependencias (pip install -e .)
- EjecuciÃ³n del script (python src/bigdata/ingestion.py)
- Commit y push de los cambios

### **TecnologÃ­as Utilizadas**
- Python (Requests, SQLite3, Pandas, OpenPyXL)
- GitHub Codespaces (para desarrollo en la nube)
- GitHub Actions (para la automatizaciÃ³n del proceso)
- SQLite (como base de datos para almacenamiento)

Este proyecto permite la extracciÃ³n y almacenamiento de datos de videojuegos de Nintendo Switch de manera estructurada y automatizada. Gracias a Codespaces, todo el desarrollo se realizÃ³ en la nube sin necesidad de configuraciones locales. AdemÃ¡s, la integraciÃ³n con GitHub Actions garantiza la ejecuciÃ³n automÃ¡tica y reproducible del proceso.

## Actividad 2: Preprocesamiento y Limpieza de Datos en Plataforma de Big Data en la Nube

### DescripciÃ³n
En esta actividad, se llevÃ³ a cabo un anÃ¡lisis exploratorio de datos (EDA) utilizando Pandas y SQLite, con el objetivo de identificar problemas de calidad en los datos. Posteriormente, se aplicaron tÃ©cnicas de limpieza para corregir estos problemas.

### Objetivos

- Cargar los datos desde una base SQLite.
- Realizar un anÃ¡lisis exploratorio para identificar:
    - Registros duplicados
    - Valores nulos
    - Inconsistencias en tipos de datos
- Introducir errores en los datos para simular problemas de calidad.
- Aplicar tÃ©cnicas de limpieza de datos para corregir los problemas detectados.
- Generar un informe de auditorÃ­a con los cambios realizados.
- Configurar un workflow en GitHub Actions para integrar el script de preprocesamiento y limpieza 

### AnÃ¡lisis Exploratorio
Se identificaron los siguientes problemas en los datos:
- Duplicados â†’ Se introdujeron 10 registros duplicados y se eliminaron en la limpieza.
- Valores nulos â†’ Se detectaron valores nulos en la columna "desarrolladores", que fueron reemplazados por "Desconocido".
- Errores en nombres â†’ Se limpiaron nombres eliminando caracteres especiales como #.
- Formato de fechas â†’ Se convirtieron a formato YYYY-MM-DD.

### TÃ©cnicas de Limpieza Aplicadas
- EliminaciÃ³n de duplicados
- ImputaciÃ³n de valores nulos
- NormalizaciÃ³n de nombres y gÃ©neros
- CorrecciÃ³n de formato en las fechas
- Transformaciones en los tipos de datos